# -*- coding: utf-8 -*-
"""musical_hybrid.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gskvPplbgcoBMelqq7rlf4KMbzuAjyLD
"""

from google.colab import files
files.upload()

import os
import shutil
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
import random

from tensorflow.keras.applications import ResNet50
from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess
from tensorflow.keras.utils import image_dataset_from_directory

from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.linear_model import LogisticRegression
from tensorflow.keras.models import Model
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.utils import load_img, img_to_array

os.makedirs("/root/.kaggle", exist_ok=True)
!mv kaggle.json /root/.kaggle/
!chmod 600 /root/.kaggle/kaggle.json

!kaggle datasets download -d nikolasgegenava/music-instruments

!unzip music-instruments.zip

!ls

import matplotlib.pyplot as plt
import numpy as np
import PIL
import tensorflow as tf

from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential

PATH = ("/content/music_instruments")

print(os.listdir(PATH))

os.listdir(("/content/music_instruments/banjo"))

PATH

from pathlib import Path

data_dir = Path("/content/music_instruments")
image_count = len(list(data_dir.glob("*/*.jpg")))
print(f"Total .jpg images: {image_count}")

data_dir.glob('*')

list(data_dir.glob('*'))

list(data_dir.glob('banjo'))

len(list(data_dir.glob('*/*.jpg')))

os.listdir('/content/music_instruments/sitar')

PIL.Image.open('/content/music_instruments/sitar/0194.jpg')

batch_size = 32
img_height = 224
img_width = 224

train_ds = tf.keras.utils.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset="training",
    label_mode = 'int',
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

val_ds = tf.keras.utils.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset="validation",
  seed=123,
    label_mode = 'int',
  image_size=(img_height, img_width),
  batch_size=batch_size)

class_names = train_ds.class_names
print(class_names)

class_names[3]

for image,label in train_ds.take(1):
    print(image.shape)
    print(label)

plt.figure(figsize=(10, 10))
for images, labels in train_ds.take(1):
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(images[i].numpy().astype("uint8"))
    plt.title(class_names[labels[i]])
    plt.axis("off")

# -----------------------------
# Phase 1: Feature Extraction using a Pretrained CNN (ResNet50)
# -----------------------------
base_model = ResNet50(weights='imagenet',
                      include_top=False,
                      pooling='avg',       # Global Average Pooling to output a fixed-length vector
                      input_shape=(224, 224, 3))

base_model.summary()

def extract_features(dataset, model):
    features = []
    labels = []
    for batch in dataset:
        imgs, lbl = batch
        # Preprocess images according to ResNet50 requirements.
        imgs = resnet_preprocess(imgs)
        # Extract features. Using predict in a loop here.
        feats = model.predict(imgs)
        features.append(feats)
        labels.append(lbl.numpy())
    features = np.concatenate(features, axis=0)
    labels = np.concatenate(labels, axis=0)
    return features, labels

X_train, y_train = extract_features(train_ds, base_model)
X_val, y_val = extract_features(val_ds, base_model)

X_train.shape

X_val.shape

X_train

# Scale features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)

# Apply PCA for dimensionality reduction
# (Adjust n_components based on your needs, explaining ~98% of variance)
pca = PCA(n_components=98)
x_train_pca = pca.fit_transform(X_train_scaled)
x_val_pca = pca.transform(X_val_scaled)

x_train_pca.shape

x_val_pca.shape

clf = LogisticRegression(random_state=42, solver='saga', max_iter=2000)
clf.fit(x_train_pca, y_train)
y_pred = clf.predict(x_val_pca)

print("Classification Report:")
print(classification_report(y_val, y_pred))

print("Confusion Matrix:")
print(confusion_matrix(y_val, y_pred))

img = tf.keras.utils.load_img("/content/istockphoto-1421388550-612x612.jpg", target_size = (224, 224))

img

img_array = tf.keras.utils.img_to_array(img)

img_array.shape

img_array = resnet_preprocess(img_array)

img_array = img_array.reshape(1,224,224,3)

img_features = base_model.predict(img_array)

img_features.shape

scaled_feat = scaler.transform(img_features)

scaled_feat.shape

reduced_feat = pca.transform(scaled_feat)

reduced_feat.shape

predictions = clf.predict(reduced_feat)

predictions

